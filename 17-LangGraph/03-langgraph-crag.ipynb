{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa6fb7f",
   "metadata": {},
   "source": [
    "# Corrective RAG\n",
    "\n",
    "- 논문: https://arxiv.org/pdf/2401.15884\n",
    "\n",
    "**배경**\n",
    "- RAG의 답변 결과는 검색된 문서의 관련성에 크게 의존적\n",
    "- 따라서, 검색이 잘못된 경우 답변에 대한 품질 우려가 됨\n",
    "\n",
    "**제안**\n",
    "- 사용자 입력 쿼리(query) 에 대하여 검색된 문서의 품질을 평가\n",
    "- 한마디로 검색된 결과가 사용자 입력 쿼리와 관련성이 높도록 쿼리를 수정(Corrective)\n",
    "\n",
    "![](https://teddylee777.github.io/images/2024-03-06-langgraph-agentic-rag/nodes-and-edges.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LANGGRAPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047f938",
   "metadata": {},
   "source": [
    "## GraphState\n",
    "\n",
    "각 노드에서 다음 노드로 전달되는 상태를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# GraphState 상태를 저장하는 용도로 사용합니다.\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # 질문\n",
    "    context: str  # 문서의 검색 결과\n",
    "    answer: str  # 답변\n",
    "    relevance: str  # 답변의 문서에 대한 관련성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d4095",
   "metadata": {},
   "source": [
    "## 노드와 엣지\n",
    "\n",
    "주요 개념\n",
    "\n",
    "- **GraphState(상태 저장 그래프)**: LangGraph는 그래프의 각 노드가 계산의 단계를 나타내며, 그래프는 계산이 진행됨에 따라 전달되고 업데이트되는 상태를 유지하는 상태 저장 그래프 개념을 중심으로 작동합니다.\n",
    "- **Node(노드)**: 노드는 LangGraph의 구성 요소입니다. 각 노드는 함수 또는 계산 단계를 나타냅니다. 입력 처리, 의사 결정, 외부 API와의 상호 작용 등 특정 작업을 수행하도록 노드를 정의할 수 있습니다.\n",
    "- **Edge(엣지)**: 에지는 그래프에서 노드를 연결하여 계산의 흐름을 정의합니다. LangGraph는 조건부 에지를 지원하므로 그래프의 현재 상태에 따라 실행할 다음 노드를 동적으로 결정할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 업스테이지 문서 관련성 체크 기능을 설정합니다. https://upstage.ai\n",
    "upstage_ground_checker = UpstageGroundednessCheck()\n",
    "\n",
    "\n",
    "# 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    retrieved_docs = pdf_retriever.invoke(state[\"question\"])\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=\"\".join([doc.page_content for doc in retrieved_docs]))\n",
    "\n",
    "\n",
    "#\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    return GraphState(\n",
    "        answer=pdf_chain.invoke(\n",
    "            {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "        ),\n",
    "        context=state[\"context\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    question = state[\"question\"]\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a professional prompt rewriter. Your task is to improve the question. Question must be written in same language. Don't narrate, just reponse an improved question.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Look at the input and try to reason about the underlying semantic intent / meaning.\"\n",
    "                \"\\n\\nHere is the initial question:\\n ------- \\n{question}\\n ------- \\n\"\n",
    "                \"\\n\\nFormulate an improved question:\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Question rewriting model\n",
    "    model = ChatAnthropic(temperature=0, model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    return GraphState(\n",
    "        context=state[\"context\"], question=response, answer=state[\"answer\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    # 관련성 체크를 실행합니다. 결과: grounded, notGrounded, notSure\n",
    "    response = upstage_ground_checker.run(\n",
    "        {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
    "    )\n",
    "    return GraphState(\n",
    "        relevance=response,\n",
    "        context=state[\"context\"],\n",
    "        answer=state[\"answer\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    return state[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6015807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드들을 정의합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve_document)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"llm_answer\", llm_answer)  # 정보 검색 노드를 추가합니다.\n",
    "workflow.add_node(\n",
    "    \"relevance_check\", relevance_check\n",
    ")  # 답변의 문서에 대한 관련성 체크 노드를 추가합니다.\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 질문을 재작성하는 노드를 추가합니다.\n",
    "\n",
    "# 각 노드들을 연결합니다.\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 -> 관련성 체크\n",
    "workflow.add_edge(\"rewrite\", \"retrieve\")  # 재작성 -> 관련성 체크\n",
    "\n",
    "# 조건부 엣지를 추가합니다.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"grounded\": END,  # 관련성이 있으면 종료합니다.\n",
    "        \"notGrounded\": \"rewrite\",  # 관련성이 없으면 다시 답변을 생성합니다.\n",
    "        \"notSure\": \"rewrite\",  # 관련성 체크 결과가 모호하다면 다시 답변을 생성합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    "    )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "except:\n",
    "    # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=11, configurable={\"thread_id\": \"CORRECTIVE-RAG\"}\n",
    ")\n",
    "\n",
    "# AgentState 객체를 활용하여 질문을 입력합니다.\n",
    "inputs = GraphState(\n",
    "    question=\"생성형 AI 가우스를 만든 회사의 2023년도 매출액은 얼마인가요?\"\n",
    ")\n",
    "\n",
    "# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "try:\n",
    "    for output in app.stream(inputs, config=config):\n",
    "        # 출력된 결과에서 키와 값을 순회합니다.\n",
    "        for key, value in output.items():\n",
    "            # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(\"---\")\n",
    "            # 출력 값을 예쁘게 출력합니다.\n",
    "            pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        # 각 출력 사이에 구분선을 추가합니다.\n",
    "        pprint.pprint(\"\\n---\\n\")\n",
    "except GraphRecursionError as e:\n",
    "    pprint.pprint(f\"Recursion limit reached: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ba184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question: \\t\", output[\"relevance_check\"][\"question\"])\n",
    "print(\"Answer: \\t\", output[\"relevance_check\"][\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance_check\"][\"relevance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8975aa",
   "metadata": {},
   "source": [
    "## LangSmith 추적\n",
    "\n",
    "- 추적: https://smith.langchain.com/public/6e0e77e3-c950-449f-87d6-206164837cd9/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
